{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPULCjSgsD6FnwkmbI3bDz4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1991Ab/Capstone-project-2-Taxi-trip-time-Prediction/blob/main/Taxi_trip_time_Prediction_individual_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a= input()\n",
        "b= input()\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "PCIR1YG8oP9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2fba5b-a07f-41e3-8177-c80b95e659c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            "b\n",
            "a\n",
            "b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  NYC Taxi Trip Time Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "ILM16xV1PD8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "bqVZBxrvPD8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUSINESS PROBLEM OVERVIEW**\n",
        "\n",
        "\n",
        "Your task is to build a model that predicts the total ride duration of taxi trips in New York City. Your primary dataset is one released by the NYC Taxi and Limousine Commission, which includes pickup time, geo-coordinates, number of passengers, and several other variables."
      ],
      "metadata": {
        "id": "jivUA-ONOwse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "from numpy import loadtxt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib import rcParams\n",
        "!pip install pymysql\n",
        "import pymysql\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.pool import NullPool\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from scipy.stats import *\n",
        "import math\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import XGBRFClassifier\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "!pip install shap==0.40.0\n",
        "import shap \n",
        "import graphviz\n",
        "sns.set_style('darkgrid') \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37da07e3-74d6-4d16-82a3-1e63fe41de35"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 977 kB/s \n",
            "\u001b[?25hInstalling collected packages: pymysql\n",
            "Successfully installed pymysql-1.0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting shap==0.40.0\n",
            "  Downloading shap-0.40.0-cp38-cp38-manylinux2010_x86_64.whl (571 kB)\n",
            "\u001b[K     |████████████████████████████████| 571 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.8/dist-packages (from shap==0.40.0) (4.64.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap==0.40.0) (0.56.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from shap==0.40.0) (1.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from shap==0.40.0) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from shap==0.40.0) (1.3.5)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.8/dist-packages (from shap==0.40.0) (21.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from shap==0.40.0) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from shap==0.40.0) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>20.9->shap==0.40.0) (3.0.9)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba->shap==0.40.0) (5.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba->shap==0.40.0) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap==0.40.0) (0.39.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba->shap==0.40.0) (3.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->shap==0.40.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->shap==0.40.0) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->shap==0.40.0) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->shap==0.40.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->shap==0.40.0) (1.2.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.40.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "# Mounting the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9a093b-2b22-414b-f563-4530142b08f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the dataset\n",
        "file_path = \"/content/drive/MyDrive/Capstone project-2/NYC Taxi Data (1).csv\"\n",
        "df = pd.read_csv(file_path)\n"
      ],
      "metadata": {
        "id": "CEhiayUv1809"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First \n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "70359028-f9c1-4890-cae1-df0f49758905"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
              "0  id2875421          2  2016-03-14 17:24:55  2016-03-14 17:32:30   \n",
              "1  id2377394          1  2016-06-12 00:43:35  2016-06-12 00:54:38   \n",
              "2  id3858529          2  2016-01-19 11:35:24  2016-01-19 12:10:48   \n",
              "3  id3504673          2  2016-04-06 19:32:31  2016-04-06 19:39:40   \n",
              "4  id2181028          2  2016-03-26 13:30:55  2016-03-26 13:38:10   \n",
              "\n",
              "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
              "0                1        -73.982155        40.767937         -73.964630   \n",
              "1                1        -73.980415        40.738564         -73.999481   \n",
              "2                1        -73.979027        40.763939         -74.005333   \n",
              "3                1        -74.010040        40.719971         -74.012268   \n",
              "4                1        -73.973053        40.793209         -73.972923   \n",
              "\n",
              "   dropoff_latitude store_and_fwd_flag  trip_duration  \n",
              "0         40.765602                  N            455  \n",
              "1         40.731152                  N            663  \n",
              "2         40.710087                  N           2124  \n",
              "3         40.706718                  N            429  \n",
              "4         40.782520                  N            435  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14cc580d-7e8d-4b80-8e32-9213f7e9d5b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>vendor_id</th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>dropoff_datetime</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>store_and_fwd_flag</th>\n",
              "      <th>trip_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id2875421</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-03-14 17:24:55</td>\n",
              "      <td>2016-03-14 17:32:30</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.982155</td>\n",
              "      <td>40.767937</td>\n",
              "      <td>-73.964630</td>\n",
              "      <td>40.765602</td>\n",
              "      <td>N</td>\n",
              "      <td>455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id2377394</td>\n",
              "      <td>1</td>\n",
              "      <td>2016-06-12 00:43:35</td>\n",
              "      <td>2016-06-12 00:54:38</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.980415</td>\n",
              "      <td>40.738564</td>\n",
              "      <td>-73.999481</td>\n",
              "      <td>40.731152</td>\n",
              "      <td>N</td>\n",
              "      <td>663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id3858529</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-01-19 11:35:24</td>\n",
              "      <td>2016-01-19 12:10:48</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.979027</td>\n",
              "      <td>40.763939</td>\n",
              "      <td>-74.005333</td>\n",
              "      <td>40.710087</td>\n",
              "      <td>N</td>\n",
              "      <td>2124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id3504673</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-04-06 19:32:31</td>\n",
              "      <td>2016-04-06 19:39:40</td>\n",
              "      <td>1</td>\n",
              "      <td>-74.010040</td>\n",
              "      <td>40.719971</td>\n",
              "      <td>-74.012268</td>\n",
              "      <td>40.706718</td>\n",
              "      <td>N</td>\n",
              "      <td>429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id2181028</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-03-26 13:30:55</td>\n",
              "      <td>2016-03-26 13:38:10</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.973053</td>\n",
              "      <td>40.793209</td>\n",
              "      <td>-73.972923</td>\n",
              "      <td>40.782520</td>\n",
              "      <td>N</td>\n",
              "      <td>435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14cc580d-7e8d-4b80-8e32-9213f7e9d5b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14cc580d-7e8d-4b80-8e32-9213f7e9d5b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14cc580d-7e8d-4b80-8e32-9213f7e9d5b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns \n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6c7b510-28cc-4bbd-e68d-6abf774ecfe3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1458644, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the NYC taxi trip time prediction data set contains 1458644 rows and 11 columns"
      ],
      "metadata": {
        "id": "2_V23HLH08TZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff973bd-8954-4b0c-9754-c5f3782882f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1458644 entries, 0 to 1458643\n",
            "Data columns (total 11 columns):\n",
            " #   Column              Non-Null Count    Dtype  \n",
            "---  ------              --------------    -----  \n",
            " 0   id                  1458644 non-null  object \n",
            " 1   vendor_id           1458644 non-null  int64  \n",
            " 2   pickup_datetime     1458644 non-null  object \n",
            " 3   dropoff_datetime    1458644 non-null  object \n",
            " 4   passenger_count     1458644 non-null  int64  \n",
            " 5   pickup_longitude    1458644 non-null  float64\n",
            " 6   pickup_latitude     1458644 non-null  float64\n",
            " 7   dropoff_longitude   1458644 non-null  float64\n",
            " 8   dropoff_latitude    1458644 non-null  float64\n",
            " 9   store_and_fwd_flag  1458644 non-null  object \n",
            " 10  trip_duration       1458644 non-null  int64  \n",
            "dtypes: float64(4), int64(3), object(4)\n",
            "memory usage: 122.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see the details of each column present in the dataset such as  their data type and count of values "
      ],
      "metadata": {
        "id": "9pA4lAiE1Y0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(df[df.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb91443-b7bc-4524-f12c-d34ab3be8df9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is very essential to check if our data set has any duplicate values and remove them if any.We can find out the duplicate values using the function dataset.duplicated().  len(dataset[dataset.duplicated()]) gives the count of duplicate values.From the above code we can see that there are no duplicate values in the dataset."
      ],
      "metadata": {
        "id": "MC6iLaZH3tE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68fcffb0-31ec-4f52-fa9b-65ba97a448c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                    0\n",
            "vendor_id             0\n",
            "pickup_datetime       0\n",
            "dropoff_datetime      0\n",
            "passenger_count       0\n",
            "pickup_longitude      0\n",
            "pickup_latitude       0\n",
            "dropoff_longitude     0\n",
            "dropoff_latitude      0\n",
            "store_and_fwd_flag    0\n",
            "trip_duration         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Checking Null Value by plotting Heatmap\n",
        "sns.heatmap(df.isnull(), cbar=True)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is very important to check for missing values or NAN values as it has a very high impact on the model.Hence identifying the NAN values and treating them becomes very important.From the above data and graph we can see that the dataset has no missing or NAN values."
      ],
      "metadata": {
        "id": "LWEeYISd5d5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset given is based on the  NYC Yellow Cab trip record data.We have to predict the taxi trip duration of various rides using various Machine Learning models.The data set has 'trip_duration' as a continous target variable and many independent variables like 'passenger_count' , 'pickup_datetime' , 'dropoff_datetime' etc.The  dataset has 1458644 rows and 11 columns.It has no NAN values and duplicate values."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "n87BaXA_42-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following are the variables used in dataset"
      ],
      "metadata": {
        "id": "z4ksAAsB-fCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* #### id - a unique identifier for each trip\n",
        "* #### vendor_id - a code indicating the provider associated with the trip record\n",
        "* #### pickup_datetime - date and time when the meter was engaged\n",
        "* #### dropoff_datetime - date and time when the meter was disengaged\n",
        "* #### passenger_count - the number of passengers in the vehicle (driver entered value)\n",
        "* #### pickup_longitude - the longitude where the meter was engaged\n",
        "* #### pickup_latitude - the latitude where the meter was engaged\n",
        "* #### dropoff_longitude - the longitude where the meter was disengaged\n",
        "* #### dropoff_latitude - the latitude where the meter was disengaged\n",
        "* #### store_and_fwd_flag - This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server - Y=store and forward; N=not a store and forward trip\n",
        "* #### trip_duration - duration of the trip in seconds"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df[i].nunique(),\".\")\n",
        "#df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Create a copy of the current dataset and assigning to df\n",
        "new_df=df.copy()\n",
        "# Checking Shape of True Value\n",
        "new_df.shape\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating the distance between pickup and dropoff locations using haversine formula"
      ],
      "metadata": {
        "id": "PaPWuHPHbnEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip  install haversine\n",
        "from numpy import math\n",
        "from haversine import haversine\n",
        "def trip_distance(df) :\n",
        "  trip_pickup=(df['pickup_latitude'], df['pickup_longitude'])\n",
        "  trip_dropoff=(df['dropoff_latitude'], df['dropoff_longitude'])\n",
        "  return haversine(trip_pickup , trip_dropoff)"
      ],
      "metadata": {
        "id": "NrK899PLgN2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating the distance and creating a new column \"distance\" in the dataset\n",
        "df['distance']=df.apply(lambda x:trip_distance(x) , axis=1)"
      ],
      "metadata": {
        "id": "-d-_JWvIbpZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['distance'].reset_index\n"
      ],
      "metadata": {
        "id": "4xoF-yzBbpb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "t9qYRB4PbpWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the customer with highest trip distance\n"
      ],
      "metadata": {
        "id": "uu3RSwCGyTvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_distance=df.groupby('id')['distance'].max().reset_index().sort_values(by='distance' , ascending=False)"
      ],
      "metadata": {
        "id": "c7oc-9h4bpUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_distance"
      ],
      "metadata": {
        "id": "gxvSzSDJz1aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graphical Representation\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['figure.figsize'] = (14,5)\n",
        "sns.barplot(x='id' , y='distance' ,  data=max_distance.head(10))"
      ],
      "metadata": {
        "id": "6-4SizNz0MSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the above plot that customer id'id2306955' has the highest distance for trip "
      ],
      "metadata": {
        "id": "teEwHeda1ceY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "hFIpRvSJ5ZRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the data type of variables 'pickup_datetime' and 'dropoff_datetime' to datetime\n",
        "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
        "df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'])"
      ],
      "metadata": {
        "id": "bamNgSRn5KcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxezIBW-OsfT"
      },
      "outputs": [],
      "source": [
        "df[\"year\"] = df[\"pickup_datetime\"].apply(lambda x: x.year)\n",
        "df[\"pickup_month\"] = df[\"pickup_datetime\"].apply(lambda x: x.month)\n",
        "df[\"dropoff_month\"] = df[\"dropoff_datetime\"].apply(lambda x: x.month)\n",
        "df[\"pickup_day\"] = df[\"pickup_datetime\"].apply(lambda x: x.weekday())\n",
        "df[\"dropoff_day\"] = df[\"dropoff_datetime\"].apply(lambda x: x.weekday())\n",
        "df[\"dropoff_time_hour\"] = df[\"dropoff_datetime\"].apply(lambda x: x.hour)\n",
        "df[\"dropoff_time_min\"] = df[\"dropoff_datetime\"].apply(lambda x: x.minute)\n",
        "df[\"pick_up_time_hour\"] = df[\"pickup_datetime\"].apply(lambda x: x.hour)\n",
        "df[\"pick_up_time_min\"] = df[\"pickup_datetime\"].apply(lambda x: x.minute)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Number of pickups done on each day of the week"
      ],
      "metadata": {
        "id": "9i56ujKV-Ogy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure, ax = plt.subplots(nrows=2, ncols = 1, figsize = (10,10))\n",
        "sns.countplot(x = 'pickup_day', data = df, ax = ax[0])\n",
        "ax[0].set_title('no of pickups done on each day of the week')\n",
        "\n",
        "sns.countplot(x = 'dropoff_day', data = df, ax=ax[1])\n",
        "ax[1].set_title('no of dropoffs done on each day of the week')\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "kvLVN_t-bpSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above plot day-'0' represents 'Monday' and is considerd as the beginning of the week. day-'6' represents Sunday,the end of the week.From the above plot we can see that the number of pickups and dropoffs are maximum for 'Friday' which is represented as day-'4'. "
      ],
      "metadata": {
        "id": "KudGZcEOCzjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now,let us analyse the trip duration for a  week"
      ],
      "metadata": {
        "id": "eVLx0s8-HCQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "duration=df.groupby(\"pickup_day\")['trip_duration'].mean().sort_values(by='trip_duration' , ascending=False)\n",
        "duration"
      ],
      "metadata": {
        "id": "GQ-v_FLaHsf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duration=df.groupby(\"pickup_day\")['trip_duration'].mean().reset_index().sort_values(by='trip_duration' , ascending=False)\n",
        "duration"
      ],
      "metadata": {
        "id": "O0oXNLKoKMY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graphical Representation\n",
        "sns.pointplot(x='pickup_day' , y='trip_duration' , data=duration)\n",
        "plt.ylabel('Trip Duration')\n",
        "plt.xlabel('Weekday')\n",
        "plt.title('Trip Duration per WeekDay')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UQsZaT5ZJSmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above plot we can infer that the duration of trip is maximum on Thursday represented as day-'3'."
      ],
      "metadata": {
        "id": "QqJOt95LLUo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GmUCfaWjP500"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us see the customer who have highest trip duration "
      ],
      "metadata": {
        "id": "AOx_SBBhxgZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_distance=df.groupby(\"id\")[\"trip_duration\"].mean().reset_index().sort_values(by=\"trip_duration\" , ascending=False)\n",
        "customer_distance\n",
        "\n"
      ],
      "metadata": {
        "id": "RzWtvo7wCmtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will find out the number of customers who travel within 30 mins,customers who travel between 30 mins to 1hr and customers who travel from 1hr to 2hr and customers who travel above 2hrs and more."
      ],
      "metadata": {
        "id": "KxtOh66oDGcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dividing the dataset on the basis of cutomer travelling time.\n",
        "#Determining the count of customers who travel within 30 mins\n",
        "df_travel_time_30=df[df[\"trip_duration\"]<=1800]\n",
        "df_travel_time_30.head()\n"
      ],
      "metadata": {
        "id": "pKq26__WDur7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_travel_time_30))"
      ],
      "metadata": {
        "id": "QwUdM2uVJZqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the above data that the count of customer travelling within 30 mins is really very large which is around 1345526"
      ],
      "metadata": {
        "id": "RrTurcuuJfXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Determinig the count of customers who travel from 30 mins to 1hour.\n",
        "df_travel_time_60=df[(df[\"trip_duration\"]<=3600)& (df[\"trip_duration\"]>1800)]\n",
        "df_travel_time_60.head()"
      ],
      "metadata": {
        "id": "hBmapjSBJ1fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_travel_time_60))"
      ],
      "metadata": {
        "id": "4A80ImwtKThT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above analysis we can see that the number of customers who travel between 30 mins to 1 hour is 100801.It is pretty less compared to number of customer who travel within 30 mins. "
      ],
      "metadata": {
        "id": "tsiVXpQdHXOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Determiming the count of customers who travel between 1 hours to 2 hours.\n",
        "df_travel_time_2hr=df[(df[\"trip_duration\"]>3600) & (df[\"trip_duration\"]<=(3600*2))]\n",
        "df_travel_time_2hr.head()"
      ],
      "metadata": {
        "id": "QmexhAbaLRrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_travel_time_2hr))"
      ],
      "metadata": {
        "id": "P8nmP4miMOQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the number of customers who travel between 1 hour to 2hour is 10064."
      ],
      "metadata": {
        "id": "ydtuRIiEMcY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Determiming the count of customers who travel for more than 2 hours.\n",
        "df_travel_time=df[df[\"trip_duration\"]>(3600*2)]\n",
        "df_travel_time.head()"
      ],
      "metadata": {
        "id": "TPzTNFK4Mah-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_travel_time))"
      ],
      "metadata": {
        "id": "2DzGijUoMaqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above analysis we can see that the number of customers having travel time of above 2 hours is 2253 which is pretty less compared to the number of customers travelling within 30 mins."
      ],
      "metadata": {
        "id": "JuXm9uiiOU1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to a perception we will get a clear view of customers and their tavel \n",
        "duration by graphical representaions.However for analysing the customers trip duration it is necessary to deep dive into the data set to unearth many insights.So I have created a new column called \"Distance\" using the haversine formula.I have analysed the customers with highest  distance and highest trip_duration.\n",
        "I have broken down the \"pickup_datetime\" column,\"droppoff_datetime\" column into 8 columns which are:-\n",
        "\"pickup_month\" , \"pick_up_time_hr\" , \"pick_up_time_min\" , \"pick_up_day\",\n",
        "\"dropoff_month\" , \"dropoff_time_hr\" , \"dropoff_time_min\" , \"dropoff_day\"\n",
        "Following are the insights that were analysed:\n",
        "\n",
        "*   The maximum cabs were booked on \"Friday\" represented as day-4\n",
        "\n",
        "*   The highest duration of trip was on \"Thursday\" reprsented as day-3\n",
        "\n",
        "*   The highest duration was done by cutomers whose booking id was 'id0053347'.\n",
        "    It is found out that the trip duration for this trip is 979.52 hours.\n",
        "\n",
        "*   The highest distance was travelled by the customers whose booking id is\n",
        "    found to be 'id2306955'.The distance travelled is approximately  1240.91\n",
        "\n",
        "*   We can see from the  data analysis that the count of customer      \n",
        "    travelling within 30 mins is really very large which is around '1345526'   \n",
        "\n",
        "*   From the above analysis it is inferred that the number of customers who \n",
        "    travelbetween 30 mins to 1 hour is 100801.It is pretty less compared to   \n",
        "    number of customer who travel within 30 mins.\n",
        "\n",
        "*   We can see that the number of customers who travel between 1 hour to 2hour \n",
        "    is 10064.It has become less when compared to the number of customer \n",
        "    travelling within 30 mins and number of customer travelling between 30 mins\n",
        "    to 1 hour\n",
        "\n",
        "*   From the above analysis we can see that the number of customers having  \n",
        "    travel time of above 2 hours is 2253 which is very less compared to the  \n",
        "    number of customers travelling within 2hrs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l7Sf9RblRrPD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6K_lXn0KE6Zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 - Horizontal Bar plot on Dependant Variable i.e., Trip Duration (Univariate)"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "sns.set_style('white')\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['figure.figsize'] = (14,5)"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.trip_duration.groupby(pd.cut(df.trip_duration, np.arange(0,9000,600))).count().plot(kind='barh')\n",
        "plt.xlabel('Trip Counts')\n",
        "plt.ylabel('Trip Duration in seconds ')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pgVpstuR6oNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    }
  ]
}